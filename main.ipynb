{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have the data locally locally saved as `/data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Artist CSV data\n",
    "#print(os.listdir(\"./\"))\n",
    "\n",
    "# get the directory \n",
    "main_direc = os.getcwd()\n",
    "print(main_direc)\n",
    "\n",
    "artist_csv_loc = os.path.join(main_direc, 'data/artists.csv')\n",
    "artists = pd.read_csv(artist_csv_loc)\n",
    "print(artists.shape)\n",
    "print(artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following approach is a modified version of the approach from [DeepArtists: Identify Artist from Art](https://www.kaggle.com/supratimhaldar/deepartist-identify-artist-from-art)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sortting the artists by number of paintings\n",
    "artists = artists.sort_values(by=['paintings'], ascending=False)\n",
    "# print(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with the top 10 artists by number of paintings\n",
    "artists_top = artists.head(10)\n",
    "artists_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring data and creating a DataFrame of all image paths with their associated artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images directories, cut down is just top 10 artists\n",
    "images_dir = os.path.join(main_direc, 'data/images/images')\n",
    "cut_down_images_dir = os.path.join(main_direc, 'data/limited_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images DataFrame\n",
    "artists_top_name = artists_top['name'].str.replace(' ', '_').values\n",
    "\n",
    "images_df = pd.DataFrame()\n",
    "for name in artists_top_name:\n",
    "    #print(glob.glob(images_dir + \"/\" + name + '/*'))\n",
    "\n",
    "    # Method 1:\n",
    "    #\n",
    "    #images_df = images_df.append(pd.DataFrame(data={'Path': glob.glob('../cs254-final-project/data/images/images/' + name + '/*'), 'Name': name}), ignore_index=True)\n",
    "\n",
    "    # Method 2:\n",
    "    #\n",
    "    images_df = pd.concat([images_df, pd.DataFrame(data={'Path': [\"data/images/images/\" + name + \"/\" + os.path.basename(x) for x in glob.glob(images_dir + \"/\" + name + '/*', )], 'Name': name})], ignore_index=True)\n",
    "\n",
    "images_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the Images DataFrame to a .csv\n",
    "# images_df.to_csv(os.path.join(main_direc, 'data/images.csv'), index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img,img_to_array,load_img\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "import tensorflow as tf\n",
    "\n",
    "def load_data(artists_csv_loc='data/artists.csv', images_dir='data/images/images'):\n",
    "    artists = pd.read_csv(artists_csv_loc)\n",
    "    print(artists.shape)\n",
    "    # print(artists)\n",
    "\n",
    "    # Creating a dataframe with the top 10 artists by number of paintings\n",
    "    artists_top = artists.sort_values(by=['paintings'], ascending=False)\n",
    "    print(artists_top)\n",
    "\n",
    "    # Images\n",
    "    artists_dir = os.listdir(images_dir) # Files are named after each artists\n",
    "\n",
    "    # Images DataFrame\n",
    "    artists_top_name = artists_top['name'].str.replace(' ', '_').values\n",
    "\n",
    "    images_df = pd.DataFrame()\n",
    "    for name in artists_top_name:\n",
    "        images_df = pd.concat([images_df, pd.DataFrame(data={'Path': glob.glob('data/images/images/' + name + '/*'), 'Name': name})], ignore_index=True)\n",
    "\n",
    "    print(images_df)\n",
    "\n",
    "    # Create Generator\n",
    "\n",
    "\n",
    "    BATCH_SIZE = 64\n",
    "\n",
    "    # image dimensions?\n",
    "    img_width, img_height = 277, 277\n",
    "\n",
    "    train_df = images_df.sample(frac=0.8, random_state=200)\n",
    "    test_df = images_df.drop(train_df.index)\n",
    "\n",
    "    if K.backend.image_data_format() == 'channels_first':\n",
    "        input_shape = (3, img_width, img_height)\n",
    "    else:\n",
    "        input_shape = (img_width, img_height, 3)\n",
    "\n",
    "    # instantiate neural network\n",
    "\n",
    "    # Train\n",
    "\n",
    "    train_generator = ImageDataGenerator(rescale=1.0 / 255,\n",
    "                                        rotation_range=20,\n",
    "                                        zoom_range=0.05,\n",
    "                                        width_shift_range=0.05,\n",
    "                                        height_shift_range=0.05,\n",
    "                                        shear_range=0.05,\n",
    "                                        horizontal_flip=True,\n",
    "                                        fill_mode=\"nearest\",\n",
    "                                        validation_split=0.15,\n",
    "                                        preprocessing_function=preprocess_input\n",
    "                                        )\n",
    "\n",
    "    test_generator = ImageDataGenerator(rescale=1.0 / 255, preprocessing_function=preprocess_input)\n",
    "\n",
    "    train_gen = train_generator.flow_from_dataframe(\n",
    "        train_df,\n",
    "        shuffle=True,\n",
    "        x_col='Path',\n",
    "        y_col='Name',\n",
    "        class_mode='categorical',\n",
    "        subset=\"training\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        target_size=(img_width, img_height),\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    valid_gen = train_generator.flow_from_dataframe(\n",
    "        train_df,\n",
    "        subset=\"validation\",\n",
    "        shuffle=True,\n",
    "        x_col='Path',\n",
    "        y_col='Name',\n",
    "        class_mode='categorical',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        target_size=(img_width, img_height),\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    test_gen = test_generator.flow_from_dataframe(\n",
    "        test_df,\n",
    "        x_col='Path',\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        class_mode=None,\n",
    "        target_size=(img_width, img_height)\n",
    "    )\n",
    "\n",
    "    return train_gen, valid_gen, test_gen\n",
    "\n",
    "train_gen, valid_gen, test_gen = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASELINE MODEL\n",
    "The following model is a simple convolutional neural network using the keras\n",
    "Sequential API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD MODEL\n",
    "num_classes = 10\n",
    "\n",
    "sequential_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "# compile model\n",
    "sequential_model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FITTING THE MODEL\n",
    "sequential_model.fit(\n",
    "  train_gen,\n",
    "  validation_data=valid_gen,\n",
    "  epochs=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following model is Clay Kaufmann's model.\n",
    "This model takes advantage of transfer learning, using Inception v3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inception\n",
    "#from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "import tensorflow.keras as K\n",
    "\n",
    "# set the input for VGG\n",
    "inp = Input(shape=(img_height,img_width,3))\n",
    "\n",
    "# load model\n",
    "base_model = InceptionV3(include_top=False, input_tensor=inp, pooling='max', weights='imagenet')\n",
    "\n",
    "# set base model to not be trainable\n",
    "base_model.trainable = False\n",
    "\n",
    "final_model = tf.keras.Sequential()\n",
    "final_model.add(base_model)\n",
    "\n",
    "final_model.add(K.layers.Flatten())\n",
    "final_model.add(K.layers.BatchNormalization())\n",
    "final_model.add(Dense(256, activation='relu'))\n",
    "final_model.add(K.layers.Dropout(0.6))\n",
    "final_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "final_model.summary()\n",
    "\n",
    "# compile model\n",
    "final_model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "final_model.fit(\n",
    "  train_ds,\n",
    "  validation_data=vals_ds,\n",
    "  epochs=3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
