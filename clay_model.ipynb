{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "import tensorflow as tf\n",
    "import keras as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get directories\n",
    "main_direc = os.getcwd()\n",
    "images_dir = os.path.join(main_direc, 'data/images/images')\n",
    "\n",
    "# csv location\n",
    "artist_csv_loc = os.path.join(main_direc, 'data/artists.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "The below section loads in the data, making necessary preprocess changes.\n",
    "Generators are used to augment the data.\n",
    "\n",
    "### Hyperparameter Section for data preprocessing\n",
    "The following code block allows you to set different hyperparams for loading in\n",
    "the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set hyperparams for the number of classes and image generators\n",
    "\"\"\"\n",
    "\n",
    "IMG_WIDTH = 299\n",
    "IMG_HEIGHT = 299\n",
    "BATCH_SIZE = 64\n",
    "NUM_ARTISTS = 10 # this is 11 to get to 10 classes, can be changed..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame management\n",
    "The following code block loads the artists csv into pandas dataframe, sorts by\n",
    "number of paintings, and makes a dataframe with the top 10 artists by painting\n",
    "count, to give us the most amount of data possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id                   name        years                         genre  \\\n",
      "8    8       Vincent van Gogh  1853 – 1890            Post-Impressionism   \n",
      "30  30            Edgar Degas  1834 - 1917                 Impressionism   \n",
      "13  13          Pablo Picasso  1881 - 1973                        Cubism   \n",
      "15  15  Pierre-Auguste Renoir  1841 - 1919                 Impressionism   \n",
      "19  19         Albrecht Dürer  1471 - 1528          Northern Renaissance   \n",
      "46  46           Paul Gauguin  1848 – 1903  Symbolism,Post-Impressionism   \n",
      "16  16         Francisco Goya  1746 - 1828                   Romanticism   \n",
      "31  31              Rembrandt  1606 - 1669                       Baroque   \n",
      "20  20          Alfred Sisley  1839 - 1899                 Impressionism   \n",
      "32  32                 Titian  1488 - 1576    High Renaissance,Mannerism   \n",
      "22  22           Marc Chagall  1887 - 1985                   Primitivism   \n",
      "\n",
      "                 nationality  \\\n",
      "8                      Dutch   \n",
      "30                    French   \n",
      "13                   Spanish   \n",
      "15                    French   \n",
      "19                    German   \n",
      "46                    French   \n",
      "16                   Spanish   \n",
      "31                     Dutch   \n",
      "20            French,British   \n",
      "32                   Italian   \n",
      "22  French,Jewish,Belarusian   \n",
      "\n",
      "                                                  bio  \\\n",
      "8   Vincent Willem van Gogh (Dutch: [ˈvɪnsɛnt ˈʋɪl...   \n",
      "30  Edgar Degas (US:  or UK: ; born Hilaire-Germai...   \n",
      "13  Pablo Ruiz Picasso (; Spanish: [ˈpaβlo piˈkaso...   \n",
      "15  Pierre-Auguste Renoir, commonly known as Augus...   \n",
      "19  Albrecht Dürer (; German: [ˈʔalbʁɛçt ˈdyːʁɐ]; ...   \n",
      "46  Eugène Henri Paul Gauguin (UK: , US: ; French:...   \n",
      "16  Francisco José de Goya y Lucientes (; Spanish:...   \n",
      "31  Rembrandt Harmenszoon van Rijn (; Dutch: [ˈrɛm...   \n",
      "20  Alfred Sisley (; French: [sislɛ]; 30 October 1...   \n",
      "32  Tiziano Vecelli or Tiziano Vecellio (pronounce...   \n",
      "22  Marc Zakharovich Chagall ( shə-GAHL; born Mois...   \n",
      "\n",
      "                                            wikipedia  paintings  \n",
      "8       http://en.wikipedia.org/wiki/Vincent_van_Gogh        877  \n",
      "30           http://en.wikipedia.org/wiki/Edgar_Degas        702  \n",
      "13         http://en.wikipedia.org/wiki/Pablo_Picasso        439  \n",
      "15  http://en.wikipedia.org/wiki/Pierre-Auguste_Re...        336  \n",
      "19        http://en.wikipedia.org/wiki/Albrecht_Dürer        328  \n",
      "46          http://en.wikipedia.org/wiki/Paul_Gauguin        311  \n",
      "16        http://en.wikipedia.org/wiki/Francisco_Goya        291  \n",
      "31             http://en.wikipedia.org/wiki/Rembrandt        262  \n",
      "20         http://en.wikipedia.org/wiki/Alfred_Sisley        259  \n",
      "32                http://en.wikipedia.org/wiki/Titian        255  \n",
      "22          http://en.wikipedia.org/wiki/Marc_Chagall        239  \n",
      "                                                   Path          Name\n",
      "0     data/images/images/Edgar_Degas/Edgar_Degas_455...   Edgar_Degas\n",
      "1     data/images/images/Edgar_Degas/Edgar_Degas_333...   Edgar_Degas\n",
      "2     data/images/images/Edgar_Degas/Edgar_Degas_47.jpg   Edgar_Degas\n",
      "3     data/images/images/Edgar_Degas/Edgar_Degas_327...   Edgar_Degas\n",
      "4     data/images/images/Edgar_Degas/Edgar_Degas_53.jpg   Edgar_Degas\n",
      "...                                                 ...           ...\n",
      "3417  data/images/images/Marc_Chagall/Marc_Chagall_5...  Marc_Chagall\n",
      "3418  data/images/images/Marc_Chagall/Marc_Chagall_4...  Marc_Chagall\n",
      "3419  data/images/images/Marc_Chagall/Marc_Chagall_6...  Marc_Chagall\n",
      "3420  data/images/images/Marc_Chagall/Marc_Chagall_9...  Marc_Chagall\n",
      "3421  data/images/images/Marc_Chagall/Marc_Chagall_8...  Marc_Chagall\n",
      "\n",
      "[3422 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Collecting Needed Images\n",
    "artists = pd.read_csv(artist_csv_loc)\n",
    "\n",
    "# Creating a dataframe with the top 10 artists by number of paintings\n",
    "artists_sort = artists.sort_values(by=['paintings'], ascending=False)\n",
    "\n",
    "# add one to reach the first 10 classes\n",
    "artists_top = artists_sort.head(NUM_ARTISTS + 1)\n",
    "print(artists_top)\n",
    "\n",
    "# Images\n",
    "artists_dir = os.listdir(images_dir) # Files are named after each artists\n",
    "\n",
    "# Images DataFrame\n",
    "artists_top_name = artists_top['name'].str.replace(' ', '_').values\n",
    "\n",
    "images_df = pd.DataFrame()\n",
    "for name in artists_top_name:\n",
    "    images_df = pd.concat([images_df, pd.DataFrame(data={'Path': glob.glob('data/images/images/' + name + '/*'), 'Name': name})], ignore_index=True)\n",
    "\n",
    "print(images_df)\n",
    "\n",
    "train_df = images_df.sample(frac=0.8, random_state=200)\n",
    "test_df = images_df.drop(train_df.index)\n",
    "\n",
    "if K.backend.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, IMG_WIDTH, IMG_HEIGHT)\n",
    "else:\n",
    "    input_shape = (IMG_WIDTH, IMG_HEIGHT, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building generators\n",
    "The next code block builds generators for augmenting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2328 validated image filenames belonging to 10 classes.\n",
      "Found 410 validated image filenames belonging to 10 classes.\n",
      "Found 684 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Build generators\n",
    "\"\"\"\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1.0 / 255,\n",
    "                                    rotation_range=20,\n",
    "                                    zoom_range=0.05,\n",
    "                                    width_shift_range=0.05,\n",
    "                                    height_shift_range=0.05,\n",
    "                                    shear_range=0.05,\n",
    "                                    horizontal_flip=True,\n",
    "                                    fill_mode=\"nearest\",\n",
    "                                    validation_split=0.15,\n",
    "                                    preprocessing_function=preprocess_input\n",
    "                                    )\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale=1.0 / 255, preprocessing_function=preprocess_input)\n",
    "\n",
    "train_gen = train_generator.flow_from_dataframe(\n",
    "    train_df,\n",
    "    shuffle=True,\n",
    "    x_col='Path',\n",
    "    y_col='Name',\n",
    "    class_mode='categorical',\n",
    "    subset=\"training\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "valid_gen = train_generator.flow_from_dataframe(\n",
    "    train_df,\n",
    "    subset=\"validation\",\n",
    "    shuffle=True,\n",
    "    x_col='Path',\n",
    "    y_col='Name',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_gen = test_generator.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='Path',\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT)\n",
    ")\n",
    "\n",
    "# Set the amount of steps for training, validation, and testing data\n",
    "# based on the batch size\n",
    "steps_train = train_gen.n//train_gen.batch_size\n",
    "steps_valid = valid_gen.n//valid_gen.batch_size\n",
    "steps_test = test_gen.n//test_gen.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASELINE MODEL\n",
    "The following model is a very simple convolutional neural network. It is not\n",
    "very accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 15:52:54.535554: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# number of epochs for the baseline model\n",
    "n_epochs = 3\n",
    "\n",
    "sequential_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(NUM_ARTISTS - 1)\n",
    "])\n",
    "\n",
    "# compile model\n",
    "sequential_model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2021-12-13 15:53:00.916270: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 123s 4s/step - loss: 2.1504 - accuracy: 0.2213 - val_loss: 2.1276 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.12758, saving model to baseline_model.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa8805b4ac0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "# FITTING THE MODEL\n",
    "# create a checkpoint for the model\n",
    "# TODO: change name of model\n",
    "checkpt = ModelCheckpoint(filepath='baseline_model.hdf5', save_best_only=True, verbose=1)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, mode='min')\n",
    "\n",
    "# Fit the model\n",
    "sequential_model.fit_generator(\n",
    "    generator = train_gen,\n",
    "    steps_per_epoch=steps_train,\n",
    "    validation_data = valid_gen,\n",
    "    validation_steps = steps_valid,\n",
    "    verbose=1,\n",
    "    epochs=1,\n",
    "    callbacks=[checkpt, early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for baseline model\n",
    "The following code blocks create plots for the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrameIterator' object has no attribute 'class_indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pk/gnzd3pkj597gwwq232x2np9h0000gn/T/ipykernel_81076/3807391738.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrameIterator' object has no attribute 'class_indices'"
     ]
    }
   ],
   "source": [
    "labels = test_gen.class_indices\n",
    "print(list(labels.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637/637 [==============================] - 17s 27ms/step\n",
      "[[-1.2984949e-01 -3.0789223e-01  7.6957518e-01 ...  6.1712111e-05\n",
      "  -2.0180282e-01 -1.9270594e-01]\n",
      " [-1.2984657e-01 -3.0788100e-01  7.6954705e-01 ...  6.3120271e-05\n",
      "  -2.0179576e-01 -1.9269826e-01]\n",
      " [-1.2985814e-01 -3.0790660e-01  7.6961011e-01 ...  6.2887440e-05\n",
      "  -2.0181060e-01 -1.9271283e-01]\n",
      " ...\n",
      " [-1.2985493e-01 -3.0790982e-01  7.6962328e-01 ...  6.2041800e-05\n",
      "  -2.0181763e-01 -1.9271894e-01]\n",
      " [-1.2983635e-01 -3.0786046e-01  7.6949191e-01 ...  6.2885578e-05\n",
      "  -2.0178154e-01 -1.9268306e-01]\n",
      " [-1.2985118e-01 -3.0789199e-01  7.6957339e-01 ...  6.2766369e-05\n",
      "  -2.0180121e-01 -1.9270451e-01]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Shapes of all inputs must match: values[0].shape = [9] != values[1].shape = [637,9] [Op:Pack] name: stack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pk/gnzd3pkj597gwwq232x2np9h0000gn/T/ipykernel_81076/910057477.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# results.to_csv(\"results.csv\",index=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mcon_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#labels = dict((v,k) for k,v in labels.items())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/confusion_matrix.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(labels, predictions, num_classes, weights, dtype, name)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m     values = (array_ops.ones_like(predictions, dtype)\n\u001b[1;32m    194\u001b[0m               if weights is None else weights)\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1422\u001b[0m                        (axis, -expanded_num_dims, expanded_num_dims))\n\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1424\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mpack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   6381\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6382\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6383\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6384\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6385\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shapes of all inputs must match: values[0].shape = [9] != values[1].shape = [637,9] [Op:Pack] name: stack"
     ]
    }
   ],
   "source": [
    "# Load model weights\n",
    "# TODO: change name of model\n",
    "sequential_model.load_weights('baseline_model.hdf5')\n",
    "\n",
    "test_gen.reset()\n",
    "y_pred = sequential_model.predict(test_gen, steps=steps_test, verbose=1)\n",
    "\n",
    "predicted_class_indices=np.argmax(y_pred,axis=1)\n",
    "\n",
    "labels = (train_gen.class_indices)\n",
    "labels = list(labels.values())\n",
    "\n",
    "# print(labels)\n",
    "# filenames=(test_gen.filenames)\n",
    "# results=pd.DataFrame({\"label\":filenames,\n",
    "#                       \"Predictions\":y_pred})\n",
    "# results.to_csv(\"results.csv\",index=False)\n",
    "\n",
    "con_mat = tf.math.confusion_matrix(labels=labels, predictions=y_pred).numpy()\n",
    "\n",
    "#labels = dict((v,k) for k,v in labels.items())\n",
    "#predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "\n",
    "#print(test_gen.get_classes(test_gen,))\n",
    "\n",
    "#con_mat = tf.math.confusion_matrix(labels=labels, predictions=y_pred).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clay's Model\n",
    "The following model was designed by Clay Kaufmann. It uses Inception V3 as a\n",
    "base line, and makes modifications from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Block\n",
    "Set different hyperparameters for the model with the following block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hyperparameters here:\n",
    "\"\"\"\n",
    "\n",
    "N_EPOCHS = 10\n",
    "LEARNING_RATE = 0.001 # 0.001 is the default for Adam set by TensorFlow\n",
    "OPTIMIZER = tf.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "LOSS_FUNCTION = tf.losses.CategoricalCrossentropy(from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Functional)    (None, 2048)              21802784  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_474 (Bat (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 22,338,090\n",
      "Trainable params: 531,210\n",
      "Non-trainable params: 21,806,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Build the model\n",
    "\"\"\"\n",
    "\n",
    "# set the input for VGG\n",
    "inp = Input(shape=(IMG_HEIGHT,IMG_WIDTH,3))\n",
    "\n",
    "# load model\n",
    "base_model = InceptionV3(include_top=False, input_tensor=inp, pooling='max', weights='imagenet')\n",
    "\n",
    "# set base model to not be trainable\n",
    "base_model.trainable = False\n",
    "\n",
    "# create sequential model\n",
    "final_model = tf.keras.Sequential()\n",
    "\n",
    "# add the base model in\n",
    "final_model.add(base_model)\n",
    "\n",
    "final_model.add(K.layers.Flatten())\n",
    "final_model.add(K.layers.BatchNormalization())\n",
    "final_model.add(Dense(256, activation='relu'))\n",
    "final_model.add(K.layers.Dropout(0.6))\n",
    "\n",
    "# this needed to be the number of artists - 1\n",
    "final_model.add(Dense(NUM_ARTISTS, activation='softmax'))\n",
    "\n",
    "final_model.summary()\n",
    "\n",
    "# compile model\n",
    "final_model.compile(\n",
    "  optimizer=OPTIMIZER,\n",
    "  loss=LOSS_FUNCTION,\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pk/gnzd3pkj597gwwq232x2np9h0000gn/T/ipykernel_73586/3127109486.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m final_model.fit_generator(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_model' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train the model\n",
    "\"\"\"\n",
    "\n",
    "# create a checkpoint for the model\n",
    "checkpt = ModelCheckpoint(filepath='clay_trained_model.hdf5', save_best_only=True, verbose=1)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, mode='min')\n",
    "\n",
    "# Fit the model\n",
    "final_model.fit_generator(\n",
    "    generator = train_gen,\n",
    "    steps_per_epoch=steps_train,\n",
    "    validation_data = valid_gen,\n",
    "    validation_steps = steps_valid,\n",
    "    verbose=1,\n",
    "    epochs=N_EPOCHS,\n",
    "    callbacks=[checkpt, early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Section\n",
    "In the following codeblocks, metrics are used and plots are created to show how\n",
    "the model performed.  \n",
    "A confusion matrix is creating, using Seaborn's heatmap feature. A\n",
    "classification report from sklearn metrics is also run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27/637 [>.............................] - ETA: 49s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pk/gnzd3pkj597gwwq232x2np9h0000gn/T/ipykernel_45615/125317628.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# make predictions using the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# collect the actual index of the predicted class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   2036\u001b[0m                   \u001b[0;34m'will be removed in a future version. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2037\u001b[0m                   'Please use `Model.predict`, which supports generators.')\n\u001b[0;32m-> 2038\u001b[0;31m     return self.predict(\n\u001b[0m\u001b[1;32m   2039\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1749\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Make predictions\n",
    "\"\"\"\n",
    "\n",
    "# Load model weights\n",
    "final_model.load_weights('clay_model_pre_fine_tune.hdf5')\n",
    "\n",
    "# make predictions using the test set\n",
    "predict = final_model.predict_generator(test_gen, steps=steps_test, verbose=1)\n",
    "\n",
    "# collect the actual index of the predicted class\n",
    "predicted_class = np.argmax(predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86        64\n",
      "           1       0.86      0.86      0.86        51\n",
      "           2       0.71      0.83      0.77       121\n",
      "           3       0.80      0.75      0.78        65\n",
      "           4       0.67      0.91      0.77        97\n",
      "           5       0.83      0.63      0.72        63\n",
      "           6       0.75      0.70      0.72        76\n",
      "           7       0.86      0.68      0.76        47\n",
      "           8       0.93      0.51      0.66        53\n",
      "\n",
      "    accuracy                           0.77       637\n",
      "   macro avg       0.81      0.75      0.77       637\n",
      "weighted avg       0.79      0.77      0.77       637\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Produce result metrics\n",
    "\"\"\"\n",
    "\n",
    "# collect the actual classes of the predictions\n",
    "r = dict(train_gen.class_indices.items())\n",
    "y_true = test_df['Name']\n",
    "y_true = [r[k] for k in y_true]\n",
    "\n",
    "# create confusion matrix\n",
    "cm = confusion_matrix(y_true, predicted_class)\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(y_true, predicted_class))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
